{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a03ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "035bb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "num_workers = 4*torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e83d075",
   "metadata": {},
   "source": [
    "https://tutorials.pytorch.kr/beginner/former_torchies/parallelism_tutorial.html\n",
    "\n",
    "- 데이터 병렬 처리(Data Parallelism)는 미니-배치를 여러 개의 더 작은 미니-배치로 자르고 각각의 작은 미니배치를 병렬적으로 연산하는 것\n",
    "- 데이터 병렬 처리는 torch.nn.DataParallel 을 사용하여 구현\n",
    "- DataParallel 로 감쌀 수 있는 모듈은 배치 차원(batch dimension)에서 여러 GPU로 병렬 처리할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e15f1d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d754ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 8,551\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5928</th>\n",
       "      <td>c_13</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>John placed the flute the violin on the table.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>bc01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>his belief that Mary kissed Bill is mistaken.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An example of these substances be tobacco.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>r-67</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The boy's loud playing of the piano drove ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>r-67</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joe is taller than I think Mary is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>cj99</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The more people arrive, the louder that it gets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is the student pictures of whom appeared ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>r-67</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I believed that Otto was wearing this hat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sandy sang.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>d_98</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mary confidently answered any objections.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_source  label label_notes  \\\n",
       "5928            c_13      0           *   \n",
       "778             bc01      1         NaN   \n",
       "4227            ks08      1         NaN   \n",
       "1435            r-67      1         NaN   \n",
       "1559            r-67      1         NaN   \n",
       "213             cj99      1         NaN   \n",
       "4883            ks08      1         NaN   \n",
       "1210            r-67      1         NaN   \n",
       "2962            l-93      1         NaN   \n",
       "6417            d_98      1         NaN   \n",
       "\n",
       "                                               sentence  \n",
       "5928     John placed the flute the violin on the table.  \n",
       "778       his belief that Mary kissed Bill is mistaken.  \n",
       "4227         An example of these substances be tobacco.  \n",
       "1435  The boy's loud playing of the piano drove ever...  \n",
       "1559                Joe is taller than I think Mary is.  \n",
       "213    The more people arrive, the louder that it gets.  \n",
       "4883  This is the student pictures of whom appeared ...  \n",
       "1210         I believed that Otto was wearing this hat.  \n",
       "2962                                        Sandy sang.  \n",
       "6417          Mary confidently answered any objections.  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a389f935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5493</th>\n",
       "      <td>I gave her so.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>Smith threw the first base the ball.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>The thief stole Mr. Smith the painting.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>What do you remember where we bought?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7524</th>\n",
       "      <td>the boy likes themselves.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentence  label\n",
       "5493                           I gave her so.      0\n",
       "2075     Smith threw the first base the ball.      0\n",
       "2656  The thief stole Mr. Smith the painting.      0\n",
       "450     What do you remember where we bought?      0\n",
       "7524                the boy likes themselves.      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83e4ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ac8dbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the BERT tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "272b1351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
      "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfb266ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  47\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89e7186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
      "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3523360/633589768.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43747bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,695 training samples\n",
      "  856 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16eb5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00864a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be663ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "537611bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23ee2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a87ee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3106edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e248a93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:22.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:34.\n",
      "  Batch   160  of    241.    Elapsed: 0:00:45.\n",
      "  Batch   200  of    241.    Elapsed: 0:00:56.\n",
      "  Batch   240  of    241.    Elapsed: 0:01:07.\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.81\n",
      "  Validation Loss: 0.42\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:22.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:34.\n",
      "  Batch   160  of    241.    Elapsed: 0:00:45.\n",
      "  Batch   200  of    241.    Elapsed: 0:00:56.\n",
      "  Batch   240  of    241.    Elapsed: 0:01:08.\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation Loss: 0.41\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:23.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:34.\n",
      "  Batch   160  of    241.    Elapsed: 0:00:46.\n",
      "  Batch   200  of    241.    Elapsed: 0:00:57.\n",
      "  Batch   240  of    241.    Elapsed: 0:01:09.\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:01:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation Loss: 0.51\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:23.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:34.\n",
      "  Batch   160  of    241.    Elapsed: 0:00:46.\n",
      "  Batch   200  of    241.    Elapsed: 0:00:57.\n",
      "  Batch   240  of    241.    Elapsed: 0:01:09.\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:01:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation Loss: 0.55\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:04:42 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = output.loss\n",
    "        logits = output.logits\n",
    "#         loss, logits = model(b_input_ids, \n",
    "#                              token_type_ids=None, \n",
    "#                              attention_mask=b_input_mask, \n",
    "#                              labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = output.loss\n",
    "            logits = output.logits\n",
    "            \n",
    "#             (loss, logits) = model(b_input_ids, \n",
    "#                                    token_type_ids=None, \n",
    "#                                    attention_mask=b_input_mask,\n",
    "#                                    labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82d7efcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0:01:07</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0:01:08</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0:01:09</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0:01:09</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.51         0.42           0.81       0:01:07         0:00:02\n",
       "2               0.32         0.41           0.84       0:01:08         0:00:02\n",
       "3               0.19         0.51           0.85       0:01:09         0:00:02\n",
       "4               0.13         0.55           0.85       0:01:09         0:00:02"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4efe4a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f86a0cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 516\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsjang/anaconda3/envs/newssum/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2211: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e624f675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 516 test sentences...\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    \n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "492efe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 354 of 516 (68.60%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fe9547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "  \n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "    # Calculate and store the coef for this batch.  \n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b661a90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a barplot showing the MCC score for each batch of test samples.\n",
    "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
    "\n",
    "plt.title('MCC Score per Batch')\n",
    "plt.ylabel('MCC Score (-1 to +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "997d6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 0.560\n"
     ]
    }
   ],
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e34ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_save/tokenizer_config.json',\n",
       " './model_save/special_tokens_map.json',\n",
       " './model_save/vocab.txt',\n",
       " './model_save/added_tokens.json')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a701fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newssum_test_4",
   "language": "python",
   "name": "newssum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
