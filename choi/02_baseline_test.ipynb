{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed 고정\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "We will use the GPU: NVIDIA TITAN RTX\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 20 17:14:42 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    On   | 00000000:18:00.0 Off |                  N/A |\n",
      "| 41%   35C    P8    15W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN RTX    On   | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 41%   35C    P8    14W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA TITAN RTX    On   | 00000000:86:00.0 Off |                  N/A |\n",
      "| 40%   35C    P8    12W / 280W |   5569MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA TITAN RTX    On   | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 41%   35C    P8    14W / 280W |  21238MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    2   N/A  N/A     27964      C   python3                          3223MiB |\n",
      "|    2   N/A  N/A     40529      C   python3                          2343MiB |\n",
      "|    3   N/A  N/A     14636      C   ailab-mrc-api                   10879MiB |\n",
      "|    3   N/A  N/A     14869      C   ailab-api-efv                    6483MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"./data\"\n",
    "TRAIN_SOURCE = os.path.join(DIR, \"train.json\")\n",
    "TEST_SOURCE = os.path.join(DIR, \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_SOURCE) as f:\n",
    "    TRAIN_DATA = json.loads(f.read())\n",
    "    \n",
    "with open(TEST_SOURCE) as f:\n",
    "    TEST_DATA = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(columns=['uid', 'title', 'region', 'context', 'summary'])\n",
    "uid = 1000\n",
    "for data in TRAIN_DATA:\n",
    "    for agenda in data['context'].keys():\n",
    "        context = ''\n",
    "        for line in data['context'][agenda]:\n",
    "            context += data['context'][agenda][line]\n",
    "            context += ' '\n",
    "        train.loc[uid, 'uid'] = uid\n",
    "        train.loc[uid, 'title'] = data['title']\n",
    "        train.loc[uid, 'region'] = data['region']\n",
    "        train.loc[uid, 'context'] = context[:-1]\n",
    "        train.loc[uid, 'summary'] = data['label'][agenda]['summary']\n",
    "        uid += 1\n",
    "\n",
    "test = pd.DataFrame(columns=['uid', 'title', 'region', 'context'])\n",
    "uid = 2000\n",
    "for data in TEST_DATA:\n",
    "    for agenda in data['context'].keys():\n",
    "        context = ''\n",
    "        for line in data['context'][agenda]:\n",
    "            context += data['context'][agenda][line]\n",
    "            context += ' '\n",
    "        test.loc[uid, 'uid'] = uid\n",
    "        test.loc[uid, 'title'] = data['title']\n",
    "        test.loc[uid, 'region'] = data['region']\n",
    "        test.loc[uid, 'context'] = context[:-1]\n",
    "        uid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['total'] = train.title + ' ' + train.region + ' ' + train.context\n",
    "test['total'] = test.title + ' ' + test.region + ' ' + test.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>title</th>\n",
       "      <th>region</th>\n",
       "      <th>context</th>\n",
       "      <th>summary</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...</td>\n",
       "      <td>제207회 완주군의회 임시회 제1차 본회의 개의 선포.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...</td>\n",
       "      <td>제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...</td>\n",
       "      <td>제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...</td>\n",
       "      <td>8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...</td>\n",
       "      <td>제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.</td>\n",
       "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                 title region  \\\n",
       "1000  1000         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1001  1001         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1002  1002         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1003  1003         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1004  1004  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록     완주   \n",
       "\n",
       "                                                context  \\\n",
       "1000  의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...   \n",
       "1001  의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...   \n",
       "1002  다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...   \n",
       "1003  다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...   \n",
       "1004  의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...   \n",
       "\n",
       "                                                summary  \\\n",
       "1000                     제207회 완주군의회 임시회 제1차 본회의 개의 선포.   \n",
       "1001   제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.   \n",
       "1002    제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.   \n",
       "1003  8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...   \n",
       "1004                 제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.   \n",
       "\n",
       "                                                  total  \n",
       "1000  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...  \n",
       "1001  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....  \n",
       "1002  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...  \n",
       "1003  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...  \n",
       "1004  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_len = 500\n",
    "decoder_len = 50\n",
    "max_vocab_size = 20000\n",
    "batch_size = 32\n",
    "num_layers = 6\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "epochs = 20\n",
    "learning_rate = 1e-4\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mecab_Tokenizer():\n",
    "    def __init__(self, max_length, mode, max_vocab_size=-1):\n",
    "        self.text_tokenizer = Mecab()\n",
    "        self.mode = mode\n",
    "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
    "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
    "        self.max_length = max_length\n",
    "        self.word_count = {}\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        \n",
    "        # 띄어쓰기를 찾기 위한 태그 목록\n",
    "        self.font_blank_tag = [\n",
    "            '', 'EC', 'EC+JKO', 'EF', 'EP+EC', 'EP+EP+EC', 'EP+ETM', 'EP+ETN+JKO', 'ETM', 'ETN', 'ETN+JKO', 'ETN+JX', 'IC', 'JC', 'JKB', 'JKB+JX', 'JKO',\n",
    "            'JKQ', 'JKS', 'JX', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ','MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+JKO', 'NNB+VCP+EC', 'NNBC', 'NNG', 'NNG+JX+JKO',\n",
    "            'NNG+VCP+EC', 'NNP', 'NNP+JX', 'NP', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NR', 'SC', 'SF', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'UNKNOWN',\n",
    "            'VA+EC', 'VA+EC+VX+ETM', 'VA+ETM', 'VA+ETN+JKB+JX', 'VCN+EC', 'VCN+ETM', 'VCP', 'VCP+EC', 'VCP+EP+EC', 'VCP+EP+ETM', 'VCP+ETM', 'VCP+ETN',\n",
    "            'VV+EC', 'VV+EC+JX', 'VV+EC+VX+EC', 'VV+EC+VX+ETM', 'VV+EP+EC', 'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VX+EC', 'VX+EC+VX+EP+EC', 'VX+EP+ETM',\n",
    "            'VX+ETM', 'XPN', 'XR', 'XSA+EC', 'XSA+EC+VX+ETM', 'XSA+ETM', 'XSN', 'XSV+EC', 'XSV+EP+EC', 'XSV+ETM', 'XSV+ETN', 'XSV+JKO'\n",
    "        ]\n",
    "        self.back_blank_tag = [\n",
    "            '', 'IC', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ', 'MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+VCP', 'NNB+VCP+EC', 'NNB+VCP+EF', 'NNBC', 'NNBC+VCP+EC',\n",
    "            'NNG', 'NNG+JC', 'NNG+JX+JKO', 'NNG+VCP', 'NNG+VCP+EC', 'NNG+VCP+ETM', 'NNP', 'NNP+JX', 'NP', 'NP+JKG', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NP+VCP+EF',\n",
    "            'NR', 'SC', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'VA', 'VA+EC', 'VA+EC+VX+ETM', 'VA+EF', 'VA+ETM', 'VA+ETN', 'VA+ETN+JKB+JX', 'VCN', 'VCN+EC', 'VCN+EF', 'VCN+ETM',\n",
    "            'VCN+ETN', 'VCP', 'VCP+EF', 'VV', 'VV+EC', 'VV+EC+JX', 'VV+EC+VX', 'VV+EC+VX+EC', 'VV+EC+VX+EF', 'VV+EC+VX+EP+EC', 'VV+EC+VX+ETM', 'VV+EF', 'VV+EP', 'VV+EP+EC',\n",
    "            'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VV+ETN+VCP+EF', 'VX', 'VX+ETM', 'XPN', 'XR', 'XSA+ETN+VCP+EF', 'XSN'\n",
    "        ]\n",
    "        \n",
    "    def morpheme(self, sentence_list):\n",
    "        new_sentence = []\n",
    "        for i, sentence in tqdm(enumerate(sentence_list)):\n",
    "            temp = []\n",
    "            if self.mode == 'dec':\n",
    "                temp.append('sos_')\n",
    "            for t in self.text_tokenizer.pos(sentence):\n",
    "                temp.append('_'.join(t))\n",
    "            if self.mode == 'dec':\n",
    "                temp.append('eos_')\n",
    "            new_sentence.append(' '.join(temp))\n",
    "            \n",
    "        return new_sentence\n",
    "    \n",
    "    def fit(self, sentence_list):\n",
    "        for sentence in tqdm(sentence_list):\n",
    "            for word in sentence.split(' '):\n",
    "                try:\n",
    "                    self.word_count[word] += 1\n",
    "                except:\n",
    "                    self.word_count[word] = 1\n",
    "        self.word_count = dict(sorted(self.word_count.items(), key=self.sort_target, reverse=True))\n",
    "        \n",
    "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
    "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
    "        if self.max_vocab_size == -1:\n",
    "            for i, word in enumerate(list(self.word_count.keys())):\n",
    "                self.txt2idx[word]=i+2\n",
    "                self.idx2txt[i+2]=word\n",
    "        else:\n",
    "            for i, word in enumerate(list(self.word_count.keys())[:self.max_vocab_size]):\n",
    "                self.txt2idx[word]=i+2\n",
    "                self.idx2txt[i+2]=word\n",
    "        \n",
    "    def sort_target(self, x):\n",
    "        return x[1]\n",
    "            \n",
    "    def txt2token(self, sentence_list):\n",
    "        tokens = []\n",
    "        for sentence in tqdm(sentence_list):\n",
    "            token = [0]*self.max_length\n",
    "            for i, w in enumerate(sentence.split(' ')):\n",
    "                if i == self.max_length:\n",
    "                    break\n",
    "                try:\n",
    "                    token[i] = self.txt2idx[w]\n",
    "                except:\n",
    "                    token[i] = self.txt2idx['unk_']\n",
    "            tokens.append(token)\n",
    "        return np.array(tokens)\n",
    "    \n",
    "    def convert(self, token):\n",
    "        sentence = []\n",
    "        for j, i in enumerate(token):\n",
    "            if self.mode == 'enc':\n",
    "                if i != self.txt2idx['pad_']:\n",
    "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
    "            elif self.mode == 'dec':\n",
    "                if i == self.txt2idx['eos_'] or i == self.txt2idx['pad_']:\n",
    "                    break\n",
    "                elif i != 0:\n",
    "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
    "                    # 앞뒤 태그를 확인하여 띄어쓰기 추가\n",
    "                    if self.idx2txt[i].split('_')[1] in self.font_blank_tag:\n",
    "                        try:\n",
    "                            if self.idx2txt[token[j+1]].split('_')[1] in self.back_blank_tag:\n",
    "                                sentence.append(' ')\n",
    "                        except:\n",
    "                            pass\n",
    "        sentence = \"\".join(sentence)\n",
    "        if self.mode == 'enc':\n",
    "            sentence = sentence[:-1]\n",
    "        elif self.mode == 'dec':\n",
    "            sentence = sentence[3:-1]\n",
    "            \n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Mecab_Tokenizer(encoder_len, mode='enc', max_vocab_size=max_vocab_size)\n",
    "tar_tokenizer = Mecab_Tokenizer(decoder_len, mode='dec', max_vocab_size=max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train.iloc[:-200]\n",
    "df_val = train.iloc[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2794it [00:10, 254.99it/s]\n",
      "200it [00:00, 275.96it/s]\n",
      "506it [00:02, 249.63it/s]\n",
      "2794it [00:00, 4938.57it/s]\n",
      "200it [00:00, 4930.33it/s]\n"
     ]
    }
   ],
   "source": [
    "train_src = src_tokenizer.morpheme(df_train.total)\n",
    "val_src = src_tokenizer.morpheme(df_val.total)\n",
    "test_src = src_tokenizer.morpheme(test.total)\n",
    "\n",
    "train_tar = tar_tokenizer.morpheme(df_train.summary)\n",
    "val_tar = tar_tokenizer.morpheme(df_val.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_src_max_len : 6476\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tar_max_len : 342\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_src_len = []\n",
    "for m in train_src:\n",
    "    m_len = len(m.split(' '))\n",
    "    train_src_len.append(m_len)\n",
    "print('train_src_max_len :', max(train_src_len))\n",
    "plt.hist(train_src_len, bins=30)\n",
    "plt.show()\n",
    "\n",
    "train_tar_len = []\n",
    "for m in train_tar:\n",
    "    m_len = len(m.split(' '))\n",
    "    train_tar_len.append(m_len)\n",
    "print('train_tar_max_len :', max(train_tar_len))\n",
    "plt.hist(train_tar_len, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2794/2794 [00:00<00:00, 5765.05it/s]\n",
      "100%|██████████| 2794/2794 [00:00<00:00, 72493.18it/s]\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer.fit(train_src)\n",
    "tar_tokenizer.fit(train_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2794/2794 [00:00<00:00, 6929.88it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 7715.44it/s]\n",
      "100%|██████████| 506/506 [00:00<00:00, 6914.75it/s]\n",
      "100%|██████████| 2794/2794 [00:00<00:00, 73494.75it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 76917.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train_src_tokens = src_tokenizer.txt2token(train_src)\n",
    "val_src_tokens = src_tokenizer.txt2token(val_src)\n",
    "test_src_tokens = src_tokenizer.txt2token(test_src)\n",
    "\n",
    "train_tar_tokens = tar_tokenizer.txt2token(train_tar)\n",
    "val_tar_tokens = tar_tokenizer.txt2token(val_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = len(src_tokenizer.txt2idx)\n",
    "target_vocab_size = len(tar_tokenizer.txt2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20002, 4877)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size, target_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tar_tokens[0], tar_tokenizer.convert(train_tar_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, src_tokens, tar_tokens, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.src_tokens = src_tokens\n",
    "        if self.mode == 'train':\n",
    "            self.tar_tokens = tar_tokens\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.src_tokens)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        src_token = self.src_tokens[i]\n",
    "        if self.mode == 'train':\n",
    "            tar_token = self.tar_tokens[i]\n",
    "            return {\n",
    "                'src_token' : torch.tensor(src_token, dtype=torch.long),\n",
    "                'tar_token' : torch.tensor(tar_token, dtype=torch.long),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'src_token' : torch.tensor(src_token, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_src_tokens, train_tar_tokens)\n",
    "val_dataset = CustomDataset(val_src_tokens, val_tar_tokens)\n",
    "test_dataset = CustomDataset(test_src_tokens, None, 'test')\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=1, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=1, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomDataset at 0x7f50448f8a10>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return torch.tensor(pos_encoding, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    seq = seq.unsqueeze(1).unsqueeze(2)\n",
    "    return seq  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = torch.ones(size, size).triu(diagonal=1)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = torch.matmul(q, torch.transpose(k, -2, -1))  # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # scale matmul_qk\n",
    "    dk = k.size()[-1]\n",
    "    scaled_attention_logits = matmul_qk / math.sqrt(dk)\n",
    "    \n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = torch.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "    print('Attention weights are:')\n",
    "    print(temp_attn)\n",
    "    print('Output is:')\n",
    "    print(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26]])\n",
      "Output is:\n",
      "tensor([[1.0000e+01, 9.2766e-25]])\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = torch.tensor([[10, 0, 0],\n",
    "                      [0, 10, 0],\n",
    "                      [0, 0, 10],\n",
    "                      [0, 0, 10]], dtype=torch.float32)  # (4, 3)\n",
    "\n",
    "temp_v = torch.tensor([[1, 0],\n",
    "                      [10, 0],\n",
    "                      [100, 5],\n",
    "                      [1000, 6]], dtype=torch.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = torch.tensor([[0, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
      "Output is:\n",
      "tensor([[5.5000e+00, 4.6383e-25]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.tensor([[10, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[4.2166e-26, 4.2166e-26, 5.0000e-01, 5.0000e-01],\n",
      "        [8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26],\n",
      "        [5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
      "Output is:\n",
      "tensor([[5.5000e+02, 5.5000e+00],\n",
      "        [1.0000e+01, 9.2766e-25],\n",
      "        [5.5000e+00, 4.6383e-25]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.tensor([[0, 0, 10],\n",
    "                      [0, 10, 0],\n",
    "                      [10, 10, 0]], dtype=torch.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.wo = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, v, k, q, mask):\n",
    "        batch_size = q.size()[0]\n",
    "        \n",
    "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = scaled_attention.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.depth)\n",
    "                \n",
    "        output = self.wo(scaled_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 60, 512]), torch.Size([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = torch.rand(1, 60, 512)  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_model, dff):\n",
    "        super(FFN, self).__init__()\n",
    "        self.layer1 = nn.Linear(d_model, dff)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc = nn.Linear(dff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FFN(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
    "        self.layernorm2 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 500, 512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048, encoder_len)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    torch.rand(64, encoder_len, 512), None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.ffn = FFN(d_model, dff)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "        self.dropout3 = nn.Dropout(rate)\n",
    "        \n",
    "        self.layernorms1 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
    "        self.layernorms2 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
    "        self.layernorms3 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorms1[x.size(1)-1](attn1 + x)\n",
    "        \n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorms2[x.size(1)-1](attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorms3[x.size(1)-1](ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 50, 512])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048, decoder_len)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    torch.rand(64, decoder_len, 512), sample_encoder_layer_output,\n",
    "    None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
    "        \n",
    "        self.dec_layers = clones(EncoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "\n",
    "    def forward(self, x, mask, enc_output=None):\n",
    "        if enc_output == None:\n",
    "            seq_len = x.size()[1]\n",
    "            attention_weights = {}\n",
    "            x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "            x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "            x += self.pos_encoding[:, :seq_len, :]\n",
    "            x = self.dropout(x)\n",
    "            for i in range(self.num_layers):\n",
    "                x = self.dec_layers[i](x, mask)\n",
    "        else:\n",
    "            x = enc_output\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 500, 512])\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, input_vocab_size=input_vocab_size,\n",
    "                         maximum_position_encoding=encoder_len,\n",
    "                         device='cpu')\n",
    "\n",
    "temp_input = torch.randint(low=0, high=input_vocab_size, size=(64, encoder_len))\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, mask=None, enc_output=None)\n",
    "\n",
    "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
    "        \n",
    "        self.dec_layers = clones(DecoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "        \n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = x.size()[1]\n",
    "        attention_weights = {}\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "            \n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 50, 512]), torch.Size([64, 8, 50, 500]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, target_vocab_size=target_vocab_size,\n",
    "                         maximum_position_encoding=decoder_len,\n",
    "                         device='cpu')\n",
    "\n",
    "temp_input = torch.randint(low=0, high=target_vocab_size, size=(64, decoder_len))\n",
    "\n",
    "output, attn = sample_decoder(temp_input,\n",
    "                              enc_output=sample_encoder_output,\n",
    "                              look_ahead_mask=None,\n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, device, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                                 input_vocab_size, pe_input, device, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, device, rate)\n",
    "\n",
    "        self.final_layer = nn.Linear(d_model, target_vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inp, tar, enc_output = inputs\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
    "\n",
    "        enc_output = self.encoder(inp, enc_padding_mask, enc_output)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights, enc_output\n",
    "\n",
    "    def create_masks(self, inp, tar):\n",
    "        # Encoder padding mask\n",
    "        enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "        # Used in the 2nd attention block in the decoder.\n",
    "        # This padding mask is used to mask the encoder outputs.\n",
    "        dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "        # Used in the 1st attention block in the decoder.\n",
    "        # It is used to pad and mask future tokens in the input received by\n",
    "        # the decoder.\n",
    "        look_ahead_mask = create_look_ahead_mask(tar.size(1))\n",
    "        dec_target_padding_mask = create_padding_mask(tar)\n",
    "        look_ahead_mask = torch.max(dec_target_padding_mask.to(self.device), look_ahead_mask.to(self.device))\n",
    "#         look_ahead_mask = torch.maximum(dec_target_padding_mask.to(self.device), look_ahead_mask.to(self.device))\n",
    "\n",
    "        return enc_padding_mask, look_ahead_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 50, 4877])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "    input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size,\n",
    "    pe_input=encoder_len, pe_target=decoder_len, device='cpu')\n",
    "\n",
    "temp_input = torch.randint(low=0, high=input_vocab_size, size=(64, encoder_len))\n",
    "temp_target = torch.randint(low=0, high=target_vocab_size, size=(64, decoder_len))\n",
    "\n",
    "fn_out, _, _ = sample_transformer([temp_input, temp_target, None])\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    pe_input=encoder_len,\n",
    "    pe_target=decoder_len-1,\n",
    "    device=device,\n",
    "    rate=dropout_rate\n",
    ")\n",
    "\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = torch.logical_not(torch.eq(real, 0))\n",
    "    loss_ = criterion(pred.permute(0,2,1), real)\n",
    "    mask = torch.tensor(mask, dtype=loss_.dtype)\n",
    "    loss_ = mask * loss_\n",
    "\n",
    "    return torch.sum(loss_)/torch.sum(mask)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = torch.eq(real, torch.argmax(pred, dim=2))\n",
    "    mask = torch.logical_not(torch.eq(real, 0))\n",
    "    accuracies = torch.logical_and(mask, accuracies)\n",
    "    accuracies = torch.tensor(accuracies, dtype=torch.float32)\n",
    "    mask = torch.tensor(mask, dtype=torch.float32)\n",
    "    \n",
    "    return torch.sum(accuracies)/torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_item, epoch, batch, training):\n",
    "    src = batch_item['src_token'].to(device)\n",
    "    tar = batch_item['tar_token'].to(device)\n",
    "    \n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    if training is True:\n",
    "        transformer.train()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output, _, _ = transformer([src, tar_inp, None])\n",
    "            loss = loss_function(tar_real, output)\n",
    "        acc = accuracy_function(tar_real, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        return loss, acc, round(lr, 10)\n",
    "    else:\n",
    "        transformer.eval()\n",
    "        with torch.no_grad():\n",
    "            output, _, _ = transformer([src, tar_inp, None])\n",
    "            loss = loss_function(tar_real, output)\n",
    "        acc = accuracy_function(tar_real, output)\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:21,  4.17it/s, Epoch=1, LR=0.0001, Loss=2.711146, Total Loss=3.962762, Total ACC=0.157340]\n",
      "7it [00:01,  5.78it/s, Epoch=1, Val Loss=6.599550, Total Val Loss=3.176756, Total Val ACC=0.321888]\n",
      "88it [00:21,  4.09it/s, Epoch=2, LR=0.0001, Loss=2.726324, Total Loss=2.508784, Total ACC=0.398225]\n",
      "7it [00:01,  5.69it/s, Epoch=2, Val Loss=6.180634, Total Val Loss=2.654505, Total Val ACC=0.422259]\n",
      "88it [00:21,  4.16it/s, Epoch=3, LR=0.0001, Loss=1.343497, Total Loss=2.120377, Total ACC=0.467136]\n",
      "7it [00:01,  5.63it/s, Epoch=3, Val Loss=5.908618, Total Val Loss=2.425099, Total Val ACC=0.463193]\n",
      "88it [00:21,  4.10it/s, Epoch=4, LR=0.0001, Loss=2.498601, Total Loss=1.914093, Total ACC=0.501673]\n",
      "7it [00:01,  5.46it/s, Epoch=4, Val Loss=5.791776, Total Val Loss=2.298753, Total Val ACC=0.486250]\n",
      "88it [00:21,  4.09it/s, Epoch=5, LR=0.0001, Loss=1.395858, Total Loss=1.755402, Total ACC=0.529641]\n",
      "7it [00:01,  5.25it/s, Epoch=5, Val Loss=5.685129, Total Val Loss=2.201792, Total Val ACC=0.504246]\n",
      "88it [00:21,  4.03it/s, Epoch=6, LR=0.0001, Loss=1.796844, Total Loss=1.638304, Total ACC=0.551060]\n",
      "7it [00:01,  5.51it/s, Epoch=6, Val Loss=5.647566, Total Val Loss=2.140998, Total Val ACC=0.515700]\n",
      "88it [00:21,  4.04it/s, Epoch=7, LR=0.0001, Loss=1.142998, Total Loss=1.530769, Total ACC=0.569582]\n",
      "7it [00:01,  5.18it/s, Epoch=7, Val Loss=5.591052, Total Val Loss=2.092050, Total Val ACC=0.526174]\n",
      "88it [00:21,  4.13it/s, Epoch=8, LR=0.0001, Loss=0.748491, Total Loss=1.443681, Total ACC=0.586064]\n",
      "7it [00:01,  5.51it/s, Epoch=8, Val Loss=5.556497, Total Val Loss=2.059466, Total Val ACC=0.532930]\n",
      "88it [00:21,  4.15it/s, Epoch=9, LR=0.0001, Loss=0.750037, Total Loss=1.362053, Total ACC=0.602042]\n",
      "7it [00:01,  5.44it/s, Epoch=9, Val Loss=5.544309, Total Val Loss=2.020940, Total Val ACC=0.541580]\n",
      "88it [00:21,  4.11it/s, Epoch=10, LR=0.0001, Loss=0.804689, Total Loss=1.286148, Total ACC=0.618816]\n",
      "7it [00:01,  5.59it/s, Epoch=10, Val Loss=5.511353, Total Val Loss=1.997626, Total Val ACC=0.550280]\n",
      "88it [00:21,  4.19it/s, Epoch=11, LR=0.0001, Loss=0.306842, Total Loss=1.209458, Total ACC=0.634416]\n",
      "7it [00:01,  5.43it/s, Epoch=11, Val Loss=5.538488, Total Val Loss=1.986169, Total Val ACC=0.553306]\n",
      "88it [00:21,  4.08it/s, Epoch=12, LR=0.0001, Loss=0.928030, Total Loss=1.151509, Total ACC=0.646034]\n",
      "7it [00:01,  5.41it/s, Epoch=12, Val Loss=5.529528, Total Val Loss=1.958995, Total Val ACC=0.565568]\n",
      "88it [00:21,  4.05it/s, Epoch=13, LR=0.0001, Loss=1.910212, Total Loss=1.092776, Total ACC=0.659416]\n",
      "7it [00:01,  5.46it/s, Epoch=13, Val Loss=5.586011, Total Val Loss=1.952327, Total Val ACC=0.567505]\n",
      "88it [00:21,  4.01it/s, Epoch=14, LR=0.0001, Loss=1.037211, Total Loss=1.027264, Total ACC=0.672811]\n",
      "7it [00:01,  5.45it/s, Epoch=14, Val Loss=5.587684, Total Val Loss=1.952855, Total Val ACC=0.567668]\n",
      "88it [00:20,  4.38it/s, Epoch=15, LR=0.0001, Loss=0.821219, Total Loss=0.969744, Total ACC=0.687946]\n",
      "7it [00:01,  5.43it/s, Epoch=15, Val Loss=5.589461, Total Val Loss=1.941666, Total Val ACC=0.569712]\n",
      "88it [00:21,  4.05it/s, Epoch=16, LR=0.0001, Loss=0.679574, Total Loss=0.911703, Total ACC=0.702853]\n",
      "7it [00:01,  5.36it/s, Epoch=16, Val Loss=5.640386, Total Val Loss=1.942287, Total Val ACC=0.571724]\n",
      "88it [00:21,  4.02it/s, Epoch=17, LR=0.0001, Loss=0.568959, Total Loss=0.859198, Total ACC=0.716599]\n",
      "7it [00:01,  5.38it/s, Epoch=17, Val Loss=5.673116, Total Val Loss=1.953519, Total Val ACC=0.576622]\n",
      "88it [00:21,  4.05it/s, Epoch=18, LR=0.0001, Loss=0.668580, Total Loss=0.805690, Total ACC=0.731676]\n",
      "7it [00:01,  5.32it/s, Epoch=18, Val Loss=5.664359, Total Val Loss=1.947377, Total Val ACC=0.576129]\n",
      "88it [00:21,  4.08it/s, Epoch=19, LR=0.0001, Loss=0.715614, Total Loss=0.760748, Total ACC=0.745247]\n",
      "7it [00:01,  5.45it/s, Epoch=19, Val Loss=5.651725, Total Val Loss=1.938772, Total Val ACC=0.580845]\n",
      "88it [00:21,  4.02it/s, Epoch=20, LR=0.0001, Loss=1.053477, Total Loss=0.711873, Total ACC=0.761580]\n",
      "7it [00:01,  5.47it/s, Epoch=20, Val Loss=5.664929, Total Val Loss=1.945481, Total Val ACC=0.578913]\n"
     ]
    }
   ],
   "source": [
    "loss_plot, val_loss_plot = [], []\n",
    "acc_plot, val_acc_plot = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    gc.collect()\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    total_acc, total_val_acc = 0, 0\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
    "    training = True\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_acc, lr = train_step(batch_item, epoch, batch, training)\n",
    "        total_loss += batch_loss\n",
    "        total_acc += batch_acc\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'LR' : lr,\n",
    "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
    "            'Total ACC' : '{:06f}'.format(total_acc/(batch+1))\n",
    "        })\n",
    "    loss_plot.append(total_loss/(batch+1))\n",
    "    acc_plot.append(total_acc/(batch+1))\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
    "    training = False\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_acc = train_step(batch_item, epoch, batch, training)\n",
    "        total_val_loss += batch_loss\n",
    "        total_val_acc += batch_acc\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
    "            'Total Val ACC' : '{:06f}'.format(total_val_acc/(batch+1))\n",
    "        })\n",
    "    val_loss_plot.append(total_val_loss/(batch+1))\n",
    "    val_acc_plot.append(total_val_acc/(batch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot, label='train_loss')\n",
    "plt.plot(val_loss_plot, label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc_plot, label='train_acc')\n",
    "plt.plot(val_acc_plot, label='val_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tokens):\n",
    "    transformer.to(device)\n",
    "    decoder_input = torch.tensor([tar_tokenizer.txt2idx['sos_']] * tokens.size(0), dtype=torch.long).to(device)\n",
    "    output = decoder_input.unsqueeze(1).to(device)\n",
    "    enc_output = None\n",
    "    for i in range(decoder_len-1):        \n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        with torch.no_grad():\n",
    "            predictions, attention_weights, enc_output = transformer([tokens, output, enc_output])\n",
    "        \n",
    "        # select the last token from the seq_len dimension\n",
    "        predictions_ = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "        \n",
    "        predicted_id = torch.tensor(torch.argmax(predictions_, axis=-1), dtype=torch.int32)\n",
    "        \n",
    "        output = torch.cat([output, predicted_id], dim=-1)\n",
    "    output = output.cpu().numpy()\n",
    "    \n",
    "    summary_list = []\n",
    "    token_list = []\n",
    "    for token in output:\n",
    "        summary = tar_tokenizer.convert(token)\n",
    "        summary_list.append(summary)\n",
    "        token_list.append(token)\n",
    "    return summary_list, token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:07,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
    "preds = []\n",
    "tokens = []\n",
    "for batch, batch_item in tqdm_dataset:\n",
    "    output = evaluate(batch_item['src_token'].to(device))\n",
    "    preds.extend(output[0])\n",
    "    tokens.extend(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답 : 음성군 경로당 지원 조례 일부개정조례안은 경로당 이용에 대한 여건 및 특수성에 따라 기존 미등록 경로당 등록기준을 완화하고, 경로당 양곡 지원에 대한 근거를 마련하는 등 경로당 이용 어르신들의 건강증진 및 복지향상에 기여하기 위해 개정함. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 장애인 가족 지원 조례 안은 < 장애인 가족 지원 사업 >의원활한 사항을 규정하고 있는 복지 증진과 동법 시행령의원활한 사항을 개정하고자 제정함. 해당 안건은 가결됨. 음성군 농\n",
      "=================================================================================\n",
      "정답 : 음성군 군세 징수 조례 일부개정조례안과 2019년 재산세 도시지역분 적용대상 지역 고시안은 <음성군 행정기구 설치 조례>가 2019년 1월 1일 전부개정됨에 따라 변경된 사항을 조례에 반영하기 위해 제정함. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 건축 조례 일부 개정 조례 안은 < 국토의계획 및 이용과 그 시행 규칙이 개정됨에 따라 음성군 군세 감면 조례로 정하도록 위임된 사항과 그 시행에 대한 재산세 안을 반영하고자 제정함. 해당 안\n",
      "=================================================================================\n",
      "정답 : 음성군 폐기물 관리 조례 일부개정조례안은 쓰레기처리비 대비 수수료 수입비율인 주민부담율이 낮아 청소행정의 건전 재정을 저해하고 불법반입 폐기물이 증가하는 문제가 있어 지역 실정에 맞도록 쓰레기 종량제 수수료를 조정하고자 제정함. 해당 안건은 가결 되었음.\n",
      "예측 :  음성군 폐기물 관리 조례 일부 개정 조례 안은 폐기물과 동법 시행령이 개정되어 있어 있어 있어 있어 있어 있어 있어 있어 있어 있어 있어 있어 있어 있어 있어 있\n",
      "=================================================================================\n",
      "정답 : 음성군 농업기계 사후관리 출장비용 지원 조례안은 음성군 농업인의 농업생산성 향상과 경영 개선, 기계화 영농 편의 등을 제공하고 농업기계 안전사용을 도모하기 위해 제정함. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 농업인 지원 사업 관리 및 지원 조례 안은 농업 인의농업 인의농업 인의농업 인의농업 인의농업 인의농업 인의농업 인 들을 위한 지원 및 농업 인의질을 위한 지원하고 \n",
      "=================================================================================\n",
      "정답 : 일반농산어촌개발사업 공유재산 시설물 관리위탁 운영 동의안은 조성한 시설물의 효율적인 관리를 위해 추진위원회에 그 재산의 관리를 위탁하고자 하는 것에 동의를 구하기 위해 발의됨. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 문화 예술 체험 촌 민간 위탁 운영 동의 안은 음성군 문화 예술 체험 촌 민간 위탁 관리 및 관리 및 관리 운영을 위해 민간 위탁 관리 사업의민간 위탁을 위해 민간 위탁을 위해 민간 위탁하고자 동의를 구함가 있\n",
      "=================================================================================\n",
      "정답 : 제251회 음성군의회 제2차 정례회 제3차 본회의 개의.\n",
      "예측 :  음성군 의회 제 3 차 정례회 3 차 본회의개의선포 . 운영은 3 월 27 일부터 3 월 27 일까지 27 일 간 음성군 의회 3 일 간 음성군 의회 3 일 간 음성군 의회 3 일 간 음성군 의회 3 일 \n",
      "=================================================================================\n",
      "정답 : 2014년도 세입 세출예산안이 가결됨. 2014년도 기금운용계획안이 가결됨.\n",
      "예측 :  2019 년도 기금 운용 계획안은 심사 결과 가결됨 . 2016 년도 기금 운용 계획안은 심사 결과 가결됨 . 2016 년도 기금 운용 계획안은 심사 결과 가결됨 . 2016 년도 기금 운용 계획안은 심사 결과 가결됨.\n",
      "=================================================================================\n",
      "정답 : 2013~2017년도 음성군 중기지방재정계획 보고. 분야별 세부사업 계획 속에 현재 진행되고 있는 사업의 보고가 누락된 부분을 시정할 것.\n",
      "예측 :  음성군 평생 학습 도시 추진을 위한 지방 공기업 법 시행령이 개정되어 있는 사업의경우가 없어 있는 것으로 인한 사업의경우에 대한 의견을 통해 사업으로 채택됨. 음성군 도시 계획 및 동법 시행령의회\n",
      "=================================================================================\n",
      "정답 : 음성군 행정기구 설치 조례 일부개정조례안은 각종 시설물과 조직을 효율적으로 관리하고자 제정되었으며, 해당 안건은 가결됨. 음성군 지방공무원 정원 조례 일부개정조례안은 총액인건비 기준 정원으로 정원을 감축함으로써 신규사업 등에 따른 각종 페널티를 방지하고 기능직 등을 일반직으로 직종 개편하고자 제안함.\n",
      "예측 :  음성군 행정 기구 설치 조례 일부 개정 조례 안은 < 지방 자치 단체를 개정하고 행정 기구 설치 및 시행 규칙 > 개정에 따라 신설 등의개정을 제안하고자 제정함. 해당 안건은 가결됨. 음성군 행정 기구 설\n",
      "=================================================================================\n",
      "정답 : 음성군 건축 조례 일부개정조례안은 법령에서 조례로 위임된 사무에 대하여 제도시행에 필요한 사항을 자치 실정에 맞도록 건축조례 일부를 개정하고자 제정되었으며, 해당 안건은 가결됨.\n",
      "예측 :  음성군 군세 조례 일부 개정 조례 안은 현행 군세 감면 조례의일부 미비점을 개선 보완하고자 제정되었으며 , 해당 안건은 가결됨. 음성군 군세 감면 조례 일부 개정 조례 안은 가결됨. 음성군 군세 감면 조례 안\n",
      "=================================================================================\n",
      "정답 : 12월 17일부터 12월 19일까지 휴회가 가결됨. 제4차 본회의는 12월 20일 오전 10시에 개의.\n",
      "예측 :  12 월 3 일부터 12 월 7 일까지 3 일 간 휴회가 가결됨 . 제 3 차 본회의는 12 월 21 일 오전 10 시에 개의.\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (a, p) in enumerate(zip(df_val.summary, preds)):\n",
    "    print('정답 :', a)\n",
    "    print('예측 :', p)\n",
    "    print('=================================================================================')\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:17,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm_dataset = tqdm(enumerate(test_dataloader))\n",
    "preds = []\n",
    "tokens = []\n",
    "for batch, batch_item in tqdm_dataset:\n",
    "    output = evaluate(batch_item['src_token'].to(device))\n",
    "    preds.extend(output[0])\n",
    "    tokens.extend(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['summary'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_2000-AGENDA_1</td>\n",
       "      <td>2006 년도 주요 사업 현지 확인 특별 위원회는 이한철 부의장 , 정태완 의원 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_2000-AGENDA_2</td>\n",
       "      <td>음성군 의회 제 217 회 제 1 차 정례회 회기는 2012 년 6 월 27 일부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_2000-AGENDA_3</td>\n",
       "      <td>제 217 회 제 1 차 정례회 회의록 서명 의원으로 반광홍 의원 , 정태완 의원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_2000-AGENDA_4</td>\n",
       "      <td>예산 결산 특별 위원회 위원은 이한철 의원 , 정태완 의원 , 남궁유 의원 , 조...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_2000-AGENDA_5</td>\n",
       "      <td>주요 사업 현지 확인 특별 위원회 구성 결의안은 6 월 30 일부터 6 월 1 일...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                uid                                            summary\n",
       "0  id_2000-AGENDA_1   2006 년도 주요 사업 현지 확인 특별 위원회는 이한철 부의장 , 정태완 의원 ...\n",
       "1  id_2000-AGENDA_2   음성군 의회 제 217 회 제 1 차 정례회 회기는 2012 년 6 월 27 일부...\n",
       "2  id_2000-AGENDA_3   제 217 회 제 1 차 정례회 회의록 서명 의원으로 반광홍 의원 , 정태완 의원...\n",
       "3  id_2000-AGENDA_4   예산 결산 특별 위원회 위원은 이한철 의원 , 정태완 의원 , 남궁유 의원 , 조...\n",
       "4  id_2000-AGENDA_5   주요 사업 현지 확인 특별 위원회 구성 결의안은 6 월 30 일부터 6 월 1 일..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv('dacon_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
