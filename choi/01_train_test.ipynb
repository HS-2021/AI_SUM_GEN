{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduction을 위한 random seed 고정\n",
    "# 대회나 논문 검증 시 등 학습한 모델을 reproduction 하기 위해 seed를 고정\n",
    "# seed 난수값 -> 난수 생성 알고리즘을 사용해 난수 생성\n",
    "# 난수 알고리즘을 실행하기 위해 쓰는 수를 seed라고 함\n",
    "# 같은 시드를 사용하면 계속 같은 패턴의 난수를 생성할 수 있음 \n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"../data\"\n",
    "TRAIN_SOURCE = os.path.join(DIR, \"train.json\")\n",
    "TEST_SOURCE = os.path.join(DIR, \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_SOURCE) as f:\n",
    "    TRAIN_DATA = json.loads(f.read())\n",
    "    \n",
    "with open(TEST_SOURCE) as f:\n",
    "    TEST_DATA = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(columns=['uid', 'title', 'region', 'context', 'summary'])\n",
    "uid = 1000\n",
    "for data in TRAIN_DATA:\n",
    "    for agenda in data['context'].keys():\n",
    "        context = ''\n",
    "        for line in data['context'][agenda]:\n",
    "            context += data['context'][agenda][line]\n",
    "            context += ' '\n",
    "        train.loc[uid, 'uid'] = uid\n",
    "        train.loc[uid, 'title'] = data['title']\n",
    "        train.loc[uid, 'region'] = data['region']\n",
    "        train.loc[uid, 'context'] = context[:-1]\n",
    "        train.loc[uid, 'summary'] = data['label'][agenda]['summary']\n",
    "        uid += 1\n",
    "\n",
    "test = pd.DataFrame(columns=['uid', 'title', 'region', 'context'])\n",
    "uid = 2000\n",
    "for data in TEST_DATA:\n",
    "    for agenda in data['context'].keys():\n",
    "        context = ''\n",
    "        for line in data['context'][agenda]:\n",
    "            context += data['context'][agenda][line]\n",
    "            context += ' '\n",
    "        test.loc[uid, 'uid'] = uid\n",
    "        test.loc[uid, 'title'] = data['title']\n",
    "        test.loc[uid, 'region'] = data['region']\n",
    "        test.loc[uid, 'context'] = context[:-1]\n",
    "        uid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['total'] = train.title + ' ' + train.region + ' ' + train.context\n",
    "test['total'] = test.title + ' ' + test.region + ' ' + test.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>title</th>\n",
       "      <th>region</th>\n",
       "      <th>context</th>\n",
       "      <th>summary</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...</td>\n",
       "      <td>제207회 완주군의회 임시회 제1차 본회의 개의 선포.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...</td>\n",
       "      <td>제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...</td>\n",
       "      <td>제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...</td>\n",
       "      <td>8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...</td>\n",
       "      <td>제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.</td>\n",
       "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                 title region  \\\n",
       "1000  1000         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1001  1001         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1002  1002         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1003  1003         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1004  1004  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록     완주   \n",
       "\n",
       "                                                context  \\\n",
       "1000  의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...   \n",
       "1001  의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...   \n",
       "1002  다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...   \n",
       "1003  다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...   \n",
       "1004  의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...   \n",
       "\n",
       "                                                summary  \\\n",
       "1000                     제207회 완주군의회 임시회 제1차 본회의 개의 선포.   \n",
       "1001   제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.   \n",
       "1002    제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.   \n",
       "1003  8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...   \n",
       "1004                 제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.   \n",
       "\n",
       "                                                  total  \n",
       "1000  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...  \n",
       "1001  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....  \n",
       "1002  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...  \n",
       "1003  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...  \n",
       "1004  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_len = 500\n",
    "decoder_len = 50\n",
    "max_vocab_size = 20000\n",
    "batch_size = 32\n",
    "num_layers = 6\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "epochs = 20\n",
    "learning_rate = 1e-4\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train.iloc[:-200]\n",
    "df_val = train.iloc[-200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mecab_Tokenizer():\n",
    "    def __init__(self, max_length, mode, max_vocab_size=-1):\n",
    "        self.text_tokenizer = Mecab()\n",
    "        self.mode = mode\n",
    "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
    "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
    "        self.max_length = max_length\n",
    "        self.word_count = {}\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        \n",
    "        # 띄어쓰기를 찾기 위한 태그 목록\n",
    "        self.font_blank_tag = [\n",
    "            '', 'EC', 'EC+JKO', 'EF', 'EP+EC', 'EP+EP+EC', 'EP+ETM', 'EP+ETN+JKO', 'ETM', 'ETN', 'ETN+JKO', 'ETN+JX', 'IC', 'JC', 'JKB', 'JKB+JX', 'JKO',\n",
    "            'JKQ', 'JKS', 'JX', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ','MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+JKO', 'NNB+VCP+EC', 'NNBC', 'NNG', 'NNG+JX+JKO',\n",
    "            'NNG+VCP+EC', 'NNP', 'NNP+JX', 'NP', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NR', 'SC', 'SF', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'UNKNOWN',\n",
    "            'VA+EC', 'VA+EC+VX+ETM', 'VA+ETM', 'VA+ETN+JKB+JX', 'VCN+EC', 'VCN+ETM', 'VCP', 'VCP+EC', 'VCP+EP+EC', 'VCP+EP+ETM', 'VCP+ETM', 'VCP+ETN',\n",
    "            'VV+EC', 'VV+EC+JX', 'VV+EC+VX+EC', 'VV+EC+VX+ETM', 'VV+EP+EC', 'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VX+EC', 'VX+EC+VX+EP+EC', 'VX+EP+ETM',\n",
    "            'VX+ETM', 'XPN', 'XR', 'XSA+EC', 'XSA+EC+VX+ETM', 'XSA+ETM', 'XSN', 'XSV+EC', 'XSV+EP+EC', 'XSV+ETM', 'XSV+ETN', 'XSV+JKO'\n",
    "        ]\n",
    "        self.back_blank_tag = [\n",
    "            '', 'IC', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ', 'MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+VCP', 'NNB+VCP+EC', 'NNB+VCP+EF', 'NNBC', 'NNBC+VCP+EC',\n",
    "            'NNG', 'NNG+JC', 'NNG+JX+JKO', 'NNG+VCP', 'NNG+VCP+EC', 'NNG+VCP+ETM', 'NNP', 'NNP+JX', 'NP', 'NP+JKG', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NP+VCP+EF',\n",
    "            'NR', 'SC', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'VA', 'VA+EC', 'VA+EC+VX+ETM', 'VA+EF', 'VA+ETM', 'VA+ETN', 'VA+ETN+JKB+JX', 'VCN', 'VCN+EC', 'VCN+EF', 'VCN+ETM',\n",
    "            'VCN+ETN', 'VCP', 'VCP+EF', 'VV', 'VV+EC', 'VV+EC+JX', 'VV+EC+VX', 'VV+EC+VX+EC', 'VV+EC+VX+EF', 'VV+EC+VX+EP+EC', 'VV+EC+VX+ETM', 'VV+EF', 'VV+EP', 'VV+EP+EC',\n",
    "            'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VV+ETN+VCP+EF', 'VX', 'VX+ETM', 'XPN', 'XR', 'XSA+ETN+VCP+EF', 'XSN'\n",
    "        ]\n",
    "        \n",
    "    def morpheme(self, sentence_list):\n",
    "        new_sentence = []\n",
    "        for i, sentence in tqdm(enumerate(sentence_list)):\n",
    "            temp = []\n",
    "            if self.mode == 'dec':\n",
    "                temp.append('sos_')\n",
    "            for t in self.text_tokenizer.pos(sentence):\n",
    "                temp.append('_'.join(t))\n",
    "            if self.mode == 'dec':\n",
    "                temp.append('eos_')\n",
    "            new_sentence.append(' '.join(temp))\n",
    "            \n",
    "        return new_sentence\n",
    "    \n",
    "    def fit(self, sentence_list):\n",
    "        for sentence in tqdm(sentence_list):\n",
    "            for word in sentence.split(' '):\n",
    "                try:\n",
    "                    self.word_count[word] += 1\n",
    "                except:\n",
    "                    self.word_count[word] = 1\n",
    "        self.word_count = dict(sorted(self.word_count.items(), key=self.sort_target, reverse=True))\n",
    "        \n",
    "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
    "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
    "        if self.max_vocab_size == -1:\n",
    "            for i, word in enumerate(list(self.word_count.keys())):\n",
    "                self.txt2idx[word]=i+2\n",
    "                self.idx2txt[i+2]=word\n",
    "        else:\n",
    "            for i, word in enumerate(list(self.word_count.keys())[:self.max_vocab_size]):\n",
    "                self.txt2idx[word]=i+2\n",
    "                self.idx2txt[i+2]=word\n",
    "        \n",
    "    def sort_target(self, x):\n",
    "        return x[1]\n",
    "            \n",
    "    def txt2token(self, sentence_list):\n",
    "        tokens = []\n",
    "        for sentence in tqdm(sentence_list):\n",
    "            token = [0]*self.max_length\n",
    "            for i, w in enumerate(sentence.split(' ')):\n",
    "                if i == self.max_length:\n",
    "                    break\n",
    "                try:\n",
    "                    token[i] = self.txt2idx[w]\n",
    "                except:\n",
    "                    token[i] = self.txt2idx['unk_']\n",
    "            tokens.append(token)\n",
    "        return np.array(tokens)\n",
    "    \n",
    "    def convert(self, token):\n",
    "        sentence = []\n",
    "        for j, i in enumerate(token):\n",
    "            if self.mode == 'enc':\n",
    "                if i != self.txt2idx['pad_']:\n",
    "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
    "            elif self.mode == 'dec':\n",
    "                if i == self.txt2idx['eos_'] or i == self.txt2idx['pad_']:\n",
    "                    break\n",
    "                elif i != 0:\n",
    "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
    "                    # 앞뒤 태그를 확인하여 띄어쓰기 추가\n",
    "                    if self.idx2txt[i].split('_')[1] in self.font_blank_tag:\n",
    "                        try:\n",
    "                            if self.idx2txt[token[j+1]].split('_')[1] in self.back_blank_tag:\n",
    "                                sentence.append(' ')\n",
    "                        except:\n",
    "                            pass\n",
    "        sentence = \"\".join(sentence)\n",
    "        if self.mode == 'enc':\n",
    "            sentence = sentence[:-1]\n",
    "        elif self.mode == 'dec':\n",
    "            sentence = sentence[3:-1]\n",
    "            \n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Mecab_Tokenizer(encoder_len, mode='enc', max_vocab_size=max_vocab_size)\n",
    "tar_tokenizer = Mecab_Tokenizer(decoder_len, mode='dec', max_vocab_size=max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2794it [00:09, 281.47it/s]\n",
      "200it [00:00, 318.22it/s]\n",
      "506it [00:01, 315.83it/s]\n",
      "2794it [00:01, 2564.93it/s]\n",
      "200it [00:00, 1356.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_src = src_tokenizer.morpheme(df_train.total)\n",
    "val_src = src_tokenizer.morpheme(df_val.total)\n",
    "test_src = src_tokenizer.morpheme(test.total)\n",
    "\n",
    "train_tar = tar_tokenizer.morpheme(df_train.summary)\n",
    "val_tar = tar_tokenizer.morpheme(df_val.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_src_max_len : 6476\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tar_max_len : 342\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_src_len = []\n",
    "for m in train_src:\n",
    "    m_len = len(m.split(' '))\n",
    "    train_src_len.append(m_len)\n",
    "print('train_src_max_len :', max(train_src_len))\n",
    "plt.hist(train_src_len, bins=30)\n",
    "plt.show()\n",
    "\n",
    "train_tar_len = []\n",
    "for m in train_tar:\n",
    "    m_len = len(m.split(' '))\n",
    "    train_tar_len.append(m_len)\n",
    "print('train_tar_max_len :', max(train_tar_len))\n",
    "plt.hist(train_tar_len, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2794/2794 [00:00<00:00, 3728.13it/s]\n",
      "100%|██████████| 2794/2794 [00:00<00:00, 43473.48it/s]\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer.fit(train_src)\n",
    "tar_tokenizer.fit(train_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2794/2794 [00:00<00:00, 5678.24it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 6650.03it/s]\n",
      "100%|██████████| 506/506 [00:00<00:00, 4425.13it/s]\n",
      "100%|██████████| 2794/2794 [00:00<00:00, 71447.03it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 53478.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train_src_tokens = src_tokenizer.txt2token(train_src)\n",
    "val_src_tokens = src_tokenizer.txt2token(val_src)\n",
    "test_src_tokens = src_tokenizer.txt2token(test_src)\n",
    "\n",
    "train_tar_tokens = tar_tokenizer.txt2token(train_tar)\n",
    "val_tar_tokens = tar_tokenizer.txt2token(val_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = len(src_tokenizer.txt2idx)\n",
    "target_vocab_size = len(tar_tokenizer.txt2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20002, 4877)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size, target_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제207회 완주군의회 임시회 제1차 본회의 개의 선포.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.summary.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   3,    8, 1131,   19,   42,   21,   24,    8,   35,   25,   49,\n",
       "           5,   44,    5,   52,    2,    4,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0]),\n",
       " ' 제 207 회 완주군 의회 임시회 제 1 차 본회의개의선포.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tar_tokens[0], tar_tokenizer.convert(train_tar_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, src_tokens, tar_tokens, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.src_tokens = src_tokens\n",
    "        if self.mode == 'train':\n",
    "            self.tar_tokens = tar_tokens\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.src_tokens)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        src_token = self.src_tokens[i]\n",
    "        if self.mode == 'train':\n",
    "            tar_token = self.tar_tokens[i]\n",
    "            return {\n",
    "                'src_token' : torch.tensor(src_token, dtype=torch.long),\n",
    "                'tar_token' : torch.tensor(tar_token, dtype=torch.long),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'src_token' : torch.tensor(src_token, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_src_tokens, train_tar_tokens)\n",
    "val_dataset = CustomDataset(val_src_tokens, val_tar_tokens)\n",
    "test_dataset = CustomDataset(test_src_tokens, None, 'test')\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=1, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=1, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return torch.tensor(pos_encoding, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    seq = seq.unsqueeze(1).unsqueeze(2)\n",
    "    return seq  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = torch.ones(size, size).triu(diagonal=1)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = torch.matmul(q, torch.transpose(k, -2, -1))  # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # scale matmul_qk\n",
    "    dk = k.size()[-1]\n",
    "    scaled_attention_logits = matmul_qk / math.sqrt(dk)\n",
    "    \n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = torch.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "    print('Attention weights are:')\n",
    "    print(temp_attn)\n",
    "    print('Output is:')\n",
    "    print(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26]])\n",
      "Output is:\n",
      "tensor([[1.0000e+01, 9.2766e-25]])\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = torch.tensor([[10, 0, 0],\n",
    "                      [0, 10, 0],\n",
    "                      [0, 0, 10],\n",
    "                      [0, 0, 10]], dtype=torch.float32)  # (4, 3)\n",
    "\n",
    "temp_v = torch.tensor([[1, 0],\n",
    "                      [10, 0],\n",
    "                      [100, 5],\n",
    "                      [1000, 6]], dtype=torch.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = torch.tensor([[0, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
      "Output is:\n",
      "tensor([[5.5000e+00, 4.6383e-25]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.tensor([[10, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_q = torch.tensor([[0, 0, 10],\n",
    "                      [0, 10, 0],\n",
    "                      [10, 10, 0]], dtype=torch.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/june/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
      "at w.execute (/Users/june/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/Users/june/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/june/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/Users/june/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/june/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
      "at w.execute (/Users/june/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/Users/june/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/june/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/Users/june/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.wo = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, v, k, q, mask):\n",
    "        batch_size = q.size()[0]\n",
    "        \n",
    "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = scaled_attention.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.depth)\n",
    "                \n",
    "        output = self.wo(scaled_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab1b603946cd54874584e3733ca987799a96e69fa454384f8c81796586d13240"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
